---
# Example: Model-Aware Validation with KServe
# This example demonstrates notebook validation against a KServe InferenceService
apiVersion: mlops.mlops.dev/v1alpha1
kind: NotebookValidationJob
metadata:
  name: model-validation-kserve-example
  namespace: mlops
spec:
  notebook:
    path: model-inference-kserve.ipynb
    git:
      url: https://github.com/tosin2013/jupyter-notebook-validator-test-notebooks.git
      ref: main
  
  podConfig:
    containerImage: quay.io/jupyter/scipy-notebook:latest
    serviceAccountName: model-validator-sa
    resources:
      requests:
        memory: "512Mi"
        cpu: "500m"
      limits:
        memory: "1Gi"
        cpu: "1000m"
  
  # Model validation configuration
  modelValidation:
    enabled: true
    platform: kserve
    phase: both  # Run both clean and existing environment validation
    
    # Target models to validate against
    targetModels:
      - fraud-detection-model
      - risk-scoring-model
    
    # Prediction validation configuration
    predictionValidation:
      enabled: true
      testData: |
        {
          "instances": [
            [1.0, 2.0, 3.0, 4.0, 5.0]
          ]
        }
      expectedOutput: |
        {
          "predictions": [
            [0.95, 0.05]
          ]
        }
      tolerance: "0.01"
    
    timeout: "5m"
  
  timeout: "30m"

---
# ServiceAccount for model validation
# This ServiceAccount needs permissions to access InferenceServices
apiVersion: v1
kind: ServiceAccount
metadata:
  name: model-validator-sa
  namespace: mlops

---
# Role for InferenceService access
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: model-validator-role
  namespace: mlops
rules:
  - apiGroups: ["serving.kserve.io"]
    resources: ["inferenceservices"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["serving.kserve.io"]
    resources: ["inferenceservices/status"]
    verbs: ["get"]

---
# RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: model-validator-rolebinding
  namespace: mlops
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: model-validator-role
subjects:
  - kind: ServiceAccount
    name: model-validator-sa
    namespace: mlops

---
# Example InferenceService (for testing)
# This is a mock InferenceService for demonstration purposes
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: fraud-detection-model
  namespace: mlops
spec:
  predictor:
    sklearn:
      storageUri: "gs://kfserving-examples/models/sklearn/1.0/model"
      resources:
        requests:
          cpu: "100m"
          memory: "256Mi"
        limits:
          cpu: "1"
          memory: "1Gi"

